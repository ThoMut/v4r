/**
 * $Id$
 * 
 * Software License Agreement (GNU General Public License)
 *
 *  Copyright (C) 2015:
 *
 *    Johann Prankl, prankl@acin.tuwien.ac.at
 *    Aitor Aldoma, aldoma@acin.tuwien.ac.at
 *
 *      Automation and Control Institute
 *      Vienna University of Technology
 *      Gusshausstra√üe 25-29
 *      1170 Vienn, Austria
 *
 *  This program is free software: you can redistribute it and/or modify
 *  it under the terms of the GNU General Public License as published by
 *  the Free Software Foundation, either version 3 of the License, or
 *  (at your option) any later version.
 *
 *  This program is distributed in the hope that it will be useful,
 *  but WITHOUT ANY WARRANTY; without even the implied warranty of
 *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *  GNU General Public License for more details.
 *
 *  You should have received a copy of the GNU General Public License
 *  along with this program.  If not, see <http://www.gnu.org/licenses/>.
 *
 * @author Johann Prankl, Aitor Aldoma
 *
 */

#ifndef _GRAB_PCD_SENSOR_H_
#define _GRAB_PCD_SENSOR_H_

#ifndef Q_MOC_RUN
#include <QThread>
#include <QMutex>
#include <queue>
#include <opencv2/opencv.hpp>
#include <pcl/point_cloud.h>
#include <pcl/point_types.h>
#include <pcl/io/openni_grabber.h>
#include <pcl/octree/octree_pointcloud_voxelcentroid.h>
#include <pcl/octree/octree.h>
#include <pcl/octree/octree_impl.h>
#include <pcl/octree/octree_pointcloud.h>
#include <pcl/filters/filter.h>
#include <pcl/filters/passthrough.h>
#include <boost/shared_ptr.hpp>
#include <pcl/common/transforms.h>
#include "params.h"
#include <v4r/keypoints/impl/Object.hpp>
#include <v4r/reconstruction/KeypointSlamRGBD2.h>
#include <v4r/common/impl/DataMatrix2D.hpp>
#include <v4r/keypoints/impl/triple.hpp>
#include <v4r/common/convertCloud.h>
#include <v4r/keypoints/ClusterNormalsToPlanes.h>
#include "OctreeVoxelCentroidContainerXYZRGB.hpp"
#include "OcclusionClustering.hh"
#endif


class Sensor : public QThread
{
  Q_OBJECT

public:
  class CameraLocation
  {
  public:
    int idx;
    int type;
    Eigen::Vector3f pt;
    Eigen::Vector3f vr;
    CameraLocation() {}
    CameraLocation(int _idx, int _type, const Eigen::Vector3f &_pt, const Eigen::Vector3f &_vr) : idx(_idx), type(_type), pt(_pt), vr(_vr) {}
  };
  /**
   * @brief The Surfel class
   */
  class Surfel
  {
  public:
    Eigen::Vector3f pt;
    Eigen::Vector3f n;
    float weight;
    float radius;
    int r, g, b;
    Surfel() : weight(0), radius(0) {}
    Surfel(const pcl::PointXYZRGB &_pt) : pt(_pt.getArray3fMap()), weight(1), radius(0), r(_pt.r), g(_pt.g), b(_pt.b) {
      if (!std::isnan(pt[0]) && !std::isnan(pt[1]) &&!std::isnan(pt[2])) {
        n = -pt.normalized();
      }
      else
      {
        n = Eigen::Vector3f(std::numeric_limits<float>::quiet_NaN(),std::numeric_limits<float>::quiet_NaN(),std::numeric_limits<float>::quiet_NaN());
        weight = 0;
      }
    }
  };

  Sensor();
  ~Sensor();

  typedef pcl::octree::OctreePointCloudVoxelCentroid<pcl::PointXYZRGB,pcl::octree::OctreeVoxelCentroidContainerXYZRGB<pcl::PointXYZRGB> >::AlignedPointTVector AlignedPointXYZRGBVector;

  void start(int cam_id=0);
  void stop();
  void startTracker(int cam_id);
  void stopTracker();
  bool isRunning();
  void reset();
  void storeKeyframes(const std::string &_folder);
  void storeCurrentFrame(const std::string& _folder);
  void storePointCloudModel(const std::string &_folder);
  const std::vector<Eigen::Matrix4f, Eigen::aligned_allocator<Eigen::Matrix4f> > &getCameras();
  void showDepthMask(bool _draw_depth_mask);
  void selectROI(int _seed_x, int _seed_y);
  void activateROI(bool enable);

  v4r::Object::Ptr &getModel() {return camtracker->getModelPtr(); }
  boost::shared_ptr< std::vector<CameraLocation> > &getTrajectory() {return cam_trajectory;}
  boost::shared_ptr< std::vector<std::pair<int, pcl::PointCloud<pcl::PointXYZRGB>::Ptr> > > &getClouds() { return log_clouds; }
  boost::shared_ptr< AlignedPointXYZRGBVector > &getAlignedCloud() {return oc_cloud;}




public slots:
  void cam_params_changed(const RGBDCameraParameter &_cam_params);
  void cam_tracker_params_changed(const CamaraTrackerParameter &_cam_tracker_params);
  void bundle_adjustment_parameter_changed(const BundleAdjustmentParameter& param);
  void select_roi(int x, int y);
  void set_roi_params(const double &_bbox_scale_xy, const double &_bbox_scale_height, const double &_seg_offs);

signals:
  void new_image(const pcl::PointCloud<pcl::PointXYZRGB>::Ptr &_cloud, const cv::Mat_<cv::Vec3b> &image);
  void new_pose(const Eigen::Matrix4f &_pose);
  void update_model_cloud(const boost::shared_ptr< Sensor::AlignedPointXYZRGBVector > &_oc_cloud);
  void update_cam_trajectory(const boost::shared_ptr< std::vector<Sensor::CameraLocation> > &_cam_trajectory);
  void update_visualization();
  void printStatus(const std::string &_txt);
  void finishedOptimizeCameras(int num_cameras);
  void update_boundingbox(const std::vector<Eigen::Vector3f> &edges, const Eigen::Matrix4f &pose);
  void set_roi(const Eigen::Vector3f &_bb_min, const Eigen::Vector3f &_bb_max, const Eigen::Matrix4f &_roi_pose);


private:
  void run();

  void CallbackCloud (const pcl::PointCloud<pcl::PointXYZRGBA>::ConstPtr &_cloud);
  int selectFrames(const pcl::PointCloud<pcl::PointXYZRGB> &cloud, int cam_id, const Eigen::Matrix4f &pose,
                   std::vector<CameraLocation> &traj);
  void renewPrevCloud(const std::vector<Eigen::Matrix4f, Eigen::aligned_allocator<Eigen::Matrix4f> > &poses, const std::vector<std::pair<int, pcl::PointCloud<pcl::PointXYZRGB>::Ptr> > &clouds);
  void drawConfidenceBar(cv::Mat &im, const double &conf);
  void drawDepthMask(const pcl::PointCloud<pcl::PointXYZRGB> &cloud, cv::Mat &im);
  void detectROI(const v4r::DataMatrix2D<Eigen::Vector3f> &cloud);
  void getInplaneTransform(const Eigen::Vector3f &pt, const Eigen::Vector3f &normal, Eigen::Matrix4f &pose);
  void getBoundingBox(const v4r::DataMatrix2D<Eigen::Vector3f> &cloud, const std::vector<int> &indices, const Eigen::Matrix4f &pose,
                      std::vector<Eigen::Vector3f> &bbox, Eigen::Vector3f &bb_min, Eigen::Vector3f &bb_max);
  void maskCloud(const Eigen::Matrix4f &pose, const Eigen::Vector3f &bb_min, const Eigen::Vector3f &bb_max, v4r::DataMatrix2D<Eigen::Vector3f> &cloud);
  void filterCloud(const pcl::PointCloud<pcl::PointXYZRGB> &_cloud, const Eigen::Matrix4f &_pose, pcl::PointCloud<pcl::PointXYZRGB> &_filt_cloud, const cv::Mat_<unsigned char> &_mask);
  void initCloud(const pcl::PointCloud<pcl::PointXYZRGB> &_cloud, const Eigen::Matrix4f &_pose, v4r::DataMatrix2D<Surfel> &_sf_cloud, Eigen::Matrix4f &_sf_pose);
  void integrateData(const pcl::PointCloud<pcl::PointXYZRGB> &_cloud, const Eigen::Matrix4f &_pose, v4r::DataMatrix2D<Surfel> &_sf_cloud, Eigen::Matrix4f &_filt_pose);

  inline bool isNaN(const Eigen::Vector3f &pt);
  inline double sqr(const double &val);



  // status
  bool m_run;
  bool m_run_tracker;
  int m_cam_id;
  bool m_draw_mask;
  bool m_select_roi;
  bool m_activate_roi;

  int roi_seed_x, roi_seed_y;
  v4r::ClusterNormalsToPlanes::Plane plane;

  // parameter
  unsigned u_idle_time;
  unsigned max_queue_size;

  RGBDCameraParameter cam_params;
  CamaraTrackerParameter cam_tracker_params;
  BundleAdjustmentParameter ba_params;

  // data logging
  double cos_min_delta_angle, sqr_min_cam_distance;
  boost::shared_ptr< std::vector<CameraLocation> > cam_trajectory;
  boost::shared_ptr< std::vector<std::pair<int, pcl::PointCloud<pcl::PointXYZRGB>::Ptr> > > log_clouds;
  std::vector<Eigen::Matrix4f, Eigen::aligned_allocator<Eigen::Matrix4f> > cameras;

  // preview
  double prev_voxel_size, prev_filter_z;
  std::vector<int> indices;
  pcl::PointCloud<pcl::PointXYZRGB>::Ptr tmp_cloud, tmp_cloud2;
  boost::shared_ptr< AlignedPointXYZRGBVector > oc_cloud;

  pcl::PassThrough<pcl::PointXYZRGB> pass;
  pcl::octree::OctreePointCloudVoxelCentroid<pcl::PointXYZRGB,pcl::octree::OctreeVoxelCentroidContainerXYZRGB<pcl::PointXYZRGB> >::Ptr octree;

  // camera tracker
  QMutex shm_mutex;
  std::queue< pcl::PointCloud<pcl::PointXYZRGB>::Ptr > shm_clouds;

  QMutex cloud_mutex;
  pcl::PointCloud<pcl::PointXYZRGB>::Ptr cloud;
  v4r::DataMatrix2D<Eigen::Vector3f> kp_cloud;
  cv::Mat_<cv::Vec3b> image;

  Eigen::Matrix4f pose;
  double conf;
  int cam_id;

  v4r::KeypointSlamRGBD2::Parameter ct_param;
  v4r::KeypointSlamRGBD2::Ptr camtracker;

  boost::shared_ptr<pcl::Grabber> interface;

  //bounding box filter
  double bbox_scale_xy, bbox_scale_height, seg_offs;
  Eigen::Vector3f bb_min, bb_max;
  std::vector<Eigen::Vector3f> edges;
  Eigen::Matrix4f bbox_base_transform;

  v4r::ClusterNormalsToPlanes::Ptr pest;
  v4r::ZAdaptiveNormals::Ptr nest;

  // filtering
  v4r::OcclusionClustering occ;
  v4r::DataMatrix2D<Surfel> sf_cloud;
  Eigen::Matrix4f sf_pose;
  cv::Mat_<unsigned char> occ_mask;

  cv::Mat_<float> depth_norm;
  cv::Mat_<float> depth_weight;
  cv::Mat_<float> tmp_z;
  cv::Mat_<float> nan_z;

  std::vector<float> exp_error_lookup;
  double max_integration_frames;
  cv::Mat_<double> cam;

};

/**
 * @brief Sensor::isNaN
 * @param pt
 * @return
 */
inline bool Sensor::isNaN(const Eigen::Vector3f &pt)
{
  if (std::isnan(pt[0]) || std::isnan(pt[1]) || std::isnan(pt[2]))
    return true;
  return false;
}

inline double Sensor::sqr(const double &val)
{
  return val*val;
}


#endif // _GRAB_PCD_SENSOR_H_
